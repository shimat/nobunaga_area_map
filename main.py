from functools import reduce
import pandas as pd
import pydeck
import re
import streamlit as st
import time
from src.area_loader import AllAreasData, load_area_data, load_region_data
from src.enums import MapType, ColorCoding
from src.town_loader import load_town_data_from_gml_zip, mod_data
from src.municipality_loader import load_municipality_borders_from_json, load_municipality_borders_from_json_multi
from src.city_list import ORG_CITY_NAMES, CITY_NAMES, SUBPREFECTURES


st.set_page_config(
    page_title="ã€Œä¿¡é•·ã®é‡æœ› å‡ºé™£ã€ã‚¨ãƒªã‚¢åˆ¥çŸ³é«˜ã®å¯è¦–åŒ–",
    page_icon="ğŸ—¾",
    layout="wide")
st.header("ã€Œä¿¡é•·ã®é‡æœ› å‡ºé™£ã€ã‚¨ãƒªã‚¢åˆ¥çŸ³é«˜ã®å¯è¦–åŒ–")

col_left, col_right = st.columns(2)

prefecture_name: str = col_left.selectbox(
    label="éƒ½é“åºœçœŒ",
    options=CITY_NAMES.keys(),
) or ""
if not prefecture_name:
    st.warning("éƒ½é“åºœçœŒã‚’é¸æŠã—ã¦ãã ã•ã„")
    st.stop()
city_name: str = col_right.selectbox(
    label="å¸‚åŒºç”ºæ‘",
    options=CITY_NAMES[prefecture_name],
    index=None,
    disabled=prefecture_name.startswith("ï¼ˆ")
) or ""
if prefecture_name.startswith("ï¼ˆ"):
    city_name = "ï¼ˆå…¨ä½“ï¼‰"
else:
    city_name = re.sub(r"^\d+: ", "", city_name)


with st.expander("ã‚ªãƒ—ã‚·ãƒ§ãƒ³"):
    col1, col2 = st.columns(2)
    with col1:
        map_type = st.radio(
            label="ãƒãƒƒãƒ—ç¨®åˆ¥",
            options=[t.value for t in MapType],
            horizontal=True,)
        color_coding_options = [t.value for t in ColorCoding]
        if map_type == MapType.ALL_TOWNS:
            color_coding_options.remove(ColorCoding.OWNERSHIP)
        color_coding = st.radio(
            label="è‰²åˆ†ã‘",
            options=color_coding_options,
            horizontal=True,)
        show_municipality_borders = st.checkbox(
            label="å¸‚åŒºç”ºæ‘å¢ƒç•Œã‚’è¡¨ç¤º",
            value=True,
            disabled=(not city_name.startswith("ï¼ˆ")))
    with col2:
        bastion_coordinates: str | None = st.text_input(
            "æ‹ ç‚¹ã®ç·¯åº¦ãƒ»çµŒåº¦ (å…¥åŠ›ã—ãŸå ´åˆã«åŠå¾„50kmã®å††ã‚’è¡¨ç¤º)", value=None, placeholder="ä¾‹: 43.0687, 141.3507")
        bastion_latitude, bastion_longitude = None, None
        if bastion_coordinates:
            try:
                bastion_latitude, bastion_longitude = map(float, bastion_coordinates.split(","))
            except:
                pass

        map_height: float = st.number_input("Mapé«˜ã•(px)", value=600, max_value=6000, min_value=100, step=10)

if city_name:
    t = time.perf_counter()
    # åœ°æ–¹å…¨ä½“ãƒ¢ãƒ¼ãƒ‰
    if prefecture_name.startswith("ï¼ˆ"):
        df_org = pd.concat([
            load_town_data_from_gml_zip(f"gml/çµŒæ¸ˆã‚»ãƒ³ã‚µã‚¹_æ´»å‹•èª¿æŸ»_{pn}.zip")
            for pn in ORG_CITY_NAMES[prefecture_name]])
    # 1ã¤ã®éƒ½é“åºœçœŒãƒ¢ãƒ¼ãƒ‰
    else:
        df_org = load_town_data_from_gml_zip(f"gml/çµŒæ¸ˆã‚»ãƒ³ã‚µã‚¹_æ´»å‹•èª¿æŸ»_{prefecture_name}.zip")
    print(f"DataFrame Load Time = {time.perf_counter() - t:.3f}s")

    t = time.perf_counter()
    if prefecture_name.startswith("ï¼ˆ"):
        area_data: AllAreasData = load_region_data(prefecture_name, ORG_CITY_NAMES[prefecture_name])
    else:
        area_data: AllAreasData = load_area_data(prefecture_name)
    print(f"AreaData Load Time = {time.perf_counter() - t:.3f}s")

    t = time.perf_counter()
    if city_name == "ï¼ˆå…¨ä½“ï¼‰" or prefecture_name.startswith("ï¼ˆ"):
        df_target = df_org[df_org["pref_city"].isin(area_data.areas.keys())].copy()
        correspondences = area_data.get_all_correspondences()
        df_mod = mod_data(df_target, correspondences, color_coding, prefecture_name)
        view_state = area_data.view_state
        st.dataframe(df_target)
        st.write(view_state)
    elif city_name.startswith("ï¼ˆ"):  # åŒ—æµ·é“ç­‰ã®å„ãƒ–ãƒ­ãƒƒã‚¯
        target_pref_cities = {f"{prefecture_name} {city_name}" for city_name in SUBPREFECTURES[prefecture_name][city_name]}
        df_target = df_org[df_org["pref_city"].isin(target_pref_cities)].copy()
        correspondences = area_data.get_multiple_areas_correspondences(target_pref_cities)
        subpref_identifier = f"{prefecture_name} {city_name}"
        df_mod = mod_data(df_target, correspondences, color_coding, subpref_identifier)
        view_state = area_data.areas[subpref_identifier].view_state
    else:
        df_target = df_org[df_org["city_name"] == city_name].copy()
        pref_city = f"{prefecture_name} {city_name}"
        correspondences = area_data.get_one_area_correspondences(pref_city)
        df_mod = mod_data(df_target, correspondences, color_coding, pref_city)
        view_state = area_data.areas[pref_city].view_state
    print(f"DataFrame Mod Time = {time.perf_counter() - t:.3f}s")
    # df_org.to_csv("hokkaido.csv", columns=["prefecture_name", "address", "area",], index=False, encoding="utf-8-sig")
    # st.write(df_org.memory_usage(deep=True))

    df_target["area_str"] = df_target["area"].apply(lambda x: "{:,.0f}".format(x))
    df_mod["area_str"] = df_mod["area"].apply(lambda x: "{:,.0f}".format(x))

    fill_color: str | list[int]
    df_show: pd.DataFrame
    match map_type:
        case MapType.NOBUNAGA_AREAS:
            df_show = df_mod
            line_width_scale = 15
            fill_color = "fill_color"
            tooltip = "{city_name} {area_name}{sub_towns_suffix}\né¢ç©: {area_str}ã¡\nçŸ³é«˜:{kokudaka_str}"
        case MapType.ALL_TOWNS:
            df_show = df_target
            line_width_scale = 10
            if color_coding == ColorCoding.RANDOM:
                fill_color = "fill_color"
            else:
                fill_color = [64, 64, 256, 64]
            tooltip = "{city_name} {town_name}\né¢ç©: {area_str}ã¡"
        case _:
            raise Exception(f"Invalid map_type '{map_type}'")

    layers: list[pydeck.Layer] = []
    layers.append(pydeck.Layer(
        "PolygonLayer",
        df_show,
        stroked=True,
        filled=True,
        extruded=False,
        wireframe=False,
        line_width_scale=line_width_scale,
        # line_width_min_pixels=0.1,
        get_polygon="lonlat_coordinates",
        get_line_color=[255, 255, 255],
        get_fill_color=fill_color,
        highlight_color=[255, 200, 0, 128],
        auto_highlight=True,
        pickable=True,
    ))
    if show_municipality_borders and city_name.startswith("ï¼ˆ"):
        t = time.perf_counter()
        if prefecture_name.startswith("ï¼ˆ"):
            df_municipalities = load_municipality_borders_from_json_multi(
                {pn: set(ORG_CITY_NAMES[pn]) for pn in ORG_CITY_NAMES[prefecture_name]})
        else:
            if city_name == "ï¼ˆå…¨ä½“ï¼‰":
                target_cities = ORG_CITY_NAMES[prefecture_name]
            else:
                target_cities = SUBPREFECTURES[prefecture_name][city_name]
            df_municipalities = load_municipality_borders_from_json(
                prefecture_name,
                set(target_cities))
        print(f"Municipality Load Time = {time.perf_counter() - t:.3f}s")
        layers.append(pydeck.Layer(
            "PolygonLayer",
            df_municipalities,
            stroked=True,
            filled=False,
            extruded=False,
            wireframe=False,
            line_width_scale=60,
            line_width_min_pixels=1,
            get_polygon="lonlat_coordinates",
            get_line_color=[255, 255, 255],
            auto_highlight=False,
            pickable=False,
        ))
    # é å¾å¯èƒ½ç¯„å›²ã®è¡¨ç¤º
    if bastion_latitude and bastion_longitude:
        df_circle = pd.DataFrame({
            "coordinates": [[bastion_longitude, bastion_latitude]] * 2,
            "radius": [50000, 300],
            "fill_color": [
                [255, 140, 0, 32],
                [255, 0, 0, 255],
            ],
        })
        layers.append(pydeck.Layer(
            "ScatterplotLayer",
            df_circle,
            pickable=False,
            stroked=True,
            filled=True,
            #radius_units="meters",
            line_width_min_pixels=1,
            get_position="coordinates",
            get_radius="radius",
            get_fill_color="fill_color",
            get_line_color=[255, 255, 255],
        ))
    deck = pydeck.Deck(
        layers=layers,
        initial_view_state=pydeck.ViewState(
            latitude=view_state.latitude,
            longitude=view_state.longitude,
            zoom=view_state.zoom,
            max_zoom=17,
            min_zoom=4,
            pitch=0,
            bearing=0,
        ),
        tooltip={"text": tooltip},
        height=map_height,
        map_provider="carto",
        map_style="dark",
    )

    # st.pydeck_chart(deck)
    st.components.v1.html(deck.to_html(as_string=True), height=map_height)

    address_label = "ä½æ‰€" if (map_type == MapType.ALL_TOWNS) else "ã‚¨ãƒªã‚¢å"
    st.dataframe(
        df_show,
        hide_index=True,
        use_container_width=True,
        column_config={
            "prefecture_name": st.column_config.TextColumn("éƒ½é“åºœçœŒ", width="small"),
            "city_name": st.column_config.TextColumn("å¸‚åŒºç”ºæ‘"),
            "area_name": st.column_config.TextColumn("ã‚¨ãƒªã‚¢å"),
            "town_name": st.column_config.TextColumn("ç”ºä¸"),
            "address": address_label,
            "area": st.column_config.NumberColumn("é¢ç©[ã¡]", step="0", width="small"),
            "kokudaka": st.column_config.NumberColumn("çŸ³é«˜", format="%.2f", width="small"),
            "kokudaka_str": None,
            "is_observed_kokudaka": st.column_config.CheckboxColumn("å®Ÿæ¸¬çŸ³é«˜ã‹", width="small", help="çŸ³é«˜ãŒå®Ÿæ¸¬å€¤ã‹ã€å›å¸°åˆ†æã«ã‚ˆã‚‹æ¨å®šå€¤ã‹ã®ãƒ•ãƒ©ã‚°"),
            # "sub_towns": st.column_config.ListColumn("å«ã‚€ç”ºå"),
            "sub_towns_suffix": None,
            "lonlat_coordinates": None,
            "pref_city": None,
            "area_str": None,
            "own": st.column_config.TextColumn("é ˜æœ‰", width="small", help="0:æœªè¸, 1:ç›´æ¥æ¥è¨ª, 2:é å¾ã§ç²å¾—"),
            "fill_color": None,
        },
    )

    if map_type != MapType.ALL_TOWNS.value:
        df_uniq = df_show.drop_duplicates(subset=("city_name", "area_name"))
        df_own = df_uniq[df_uniq["own"] != 0]
        kokudaka_all_sum = df_uniq["kokudaka"].sum()
        kokudaka_own_sum = df_own["kokudaka"].sum()
        st.write(f"æ¨å®šçŸ³é«˜åˆè¨ˆ: {kokudaka_own_sum:.2f}çŸ³ / {kokudaka_all_sum:.2f}çŸ³ ({kokudaka_own_sum/kokudaka_all_sum:.1%})")


st.markdown(
    """
-----

åˆ©ç”¨ãƒ‡ãƒ¼ã‚¿:
+ [e-Stat çµ±è¨ˆã§è¦‹ã‚‹æ—¥æœ¬](https://www.e-stat.go.jp/gis/statmap-search?page=1&type=2&aggregateUnitForBoundary=A&toukeiCode=00200553&toukeiYear=2016&serveyId=A002005532016&coordsys=1&format=gml&datum=2011): çµŒæ¸ˆã‚»ãƒ³ã‚µã‚¹ï¼æ´»å‹•èª¿æŸ»ï¼ˆç·å‹™çœãƒ»çµŒæ¸ˆç”£æ¥­çœï¼‰/ 2016å¹´ / å°åœ°åŸŸï¼ˆç”ºä¸ãƒ»å¤§å­—ï¼‰ï¼ˆJGD2011ï¼‰
+ [ã€å›½åœŸæ•°å€¤æƒ…å ±ã€Œâ¾æ”¿åŒºåŸŸãƒ‡ãƒ¼ã‚¿ã€ (N03)ã€ï¼ˆå›½åœŸäº¤é€šçœï¼‰](https://nlftp.mlit.go.jp/ksj/gml/datalist/KsjTmplt-N03-v3_1.html)
""",  # noqa: E501
    unsafe_allow_html=True,
)

